from utils.text_to_sql import *
from modules.chain import *
from modules.node import SQLGenerator
from utils.sql_to_excel import ExcelTemplateApplier
from utils.history import ConversationHistory
from utils.util import check_yes, wrapped_string_generator, wrapped_event
from utils.search import get_search_contents
from loguru import logger


def check_chain(input_data: str, extract_info: ExtractInfo, userDB: dict, session_id: str, category):
    '''
    ì…ë ¥ í…ìŠ¤íŠ¸ì— í•­êµ¬ì •ë³´, ì‹œê°„ ì •ë³´ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ëŠ” chain

    message : ì‚¬ìš©ì ì…ë ¥ ë¬¸ì¥ / ì´ì „ëŒ€í™” ìˆì„ ê²½ìš° Chain__rewrite_request ìœ¼ë¡œ ë³€ê²½í•´ì„œ ì ìš©
    extract_info : í•­ë§Œê¸°ë³¸ ì •ë³´ class
    '''
    logger.warning(f"input_data :{input_data}")
    userDB.add_init_input(session_id, input_data, category)
    input_prompt = userDB.get_init_input(session_id, category)
    logger.warning(f"input_prompt :{input_prompt}")
    state = {
        "MESSAGE": input_prompt,
        "PORT_DATA_LST": extract_info.PORT_NAME_LST,
        "FAC_NAME_LST": extract_info.FAC_NAME_LST,
        "COUNTRY_LIST": extract_info.COUNTRY_NAME_LST
    }
    # logger.warning(f"state : {state}")
    user_info = {"USE_PORT": check_yes(Chain__check_port.invoke(state).content),
                 "USE_TIME": check_yes(Chain__check_time.invoke(state).content)}
    # return info_check, response
    error_messages = {"USE_PORT": "â›” í•­êµ¬ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. ê°’ì„ ì •í™•íˆ ê¸°ì…í•´ì£¼ì„¸ìš”. ì˜ˆ:ë¶€ì‚°í•­",
                      "USE_TIME": "â›” ì‹œê°„ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. ê°’ì„ ì •í™•íˆ ê¸°ì…í•´ì£¼ì„¸ìš”. ì˜ˆ:ìµœê·¼ 2ë…„ê°„, 2020~2022 ë™ì•ˆ"}
    for key, error_message in error_messages.items():
        if user_info.get(key) != "YES":
            # logger.warning(error_message)
            # userDB.add_init_input(session_id, input_data, category)
            return False, error_message, user_info
    return True, '', user_info


def sql_chain(
        userDB: dict, session_id: str, input_data: str, input_prompt: str, category: str,
        statistics_info: dict, extract_info: dict, conv_history, message_id: str,
        screen_type: str, file_name: str = ''):
    '''
    ì…ë ¥ í…ìŠ¤íŠ¸ì— ëŒ€í•œ sql ìƒì„± chain

    user_info : dummy_userì˜ ì •ë³´
    message : ì´ì „ ëŒ€í™” ë‚´ìš© + ì‚¬ìš©ì ì…ë ¥ ë°ì´í„° ë˜ëŠ” ì‚¬ìš©ì ì…ë ¥ ë°ì´í„°
    category : ëŒ€í™” ì¢…ë¥˜
    input_data: ì§ì „ ì‚¬ìš©ìê°€ ì…ë ¥í•œ í…ìŠ¤íŠ¸
    input_prompt: ì‚¬ìš©ì ì…ë ¥ + í•­êµ¬ + ì‹œê°„ì •ë³´
    '''
    # ì¼ë°˜ ì²´ì¸
    user_info = userDB.get_user_info(session_id, category)
    template_upload = user_info['btn1']
    use_template_cols = user_info['btn2']
    # ì…ë ¥ ë°ì´í„° promptë¥¼ ìœ„í•œ class ëª¨ë“ˆí™”
    excel_applier = ExcelTemplateApplier(copy.deepcopy(input_prompt))
    # í”„ë¡¬í”„íŠ¸ ìœ í˜• ì„ íƒ ë°˜ì˜
    if template_upload:  # temp : True
        excel_path = user_info['upload']
        logger.warning(f"excel_path : {excel_path}")
        if use_template_cols:  # temp : True / use : False
            excel_applier.yes_template_common_parts(excel_path)
        else:  # temp: True / use : False
            excel_applier.yes_template_common_parts(excel_path)
            excel_applier.COLS = []
    else:  # temp: False
        pass
    # ì²´ì¸ ì •ì˜
    sql_obj = SQLGenerator(
        input_prompt,
        extract_info,
        excel_applier,
        category)
    # ë°ì´í„° ë² ì´ìŠ¤ë¡œë¶€í„° ë°ì´í„° ì¶”ì¶œ
    sql_obj.STATE = {
        "MESSAGE": input_prompt,
        "PORT_DATA_LST": extract_info.PORT_NAME_LST,
        "FAC_NAME_LST": extract_info.FAC_NAME_LST,
        "COUNTRY_LIST": extract_info.COUNTRY_NAME_LST
    }
    sql_obj.USE_INFO = statistics_info
    sql_obj.Node__extract_info()

    # SQLë¬¸ ìƒì„± chain ë™ì‘
    save_response = ''
    response_init = '\n### SQLë¬¸ ìƒì„±\n'
    save_response += response_init
    logger.warning(f"file_name : {file_name}")
    if len(file_name) != 0:
        yield wrapped_event(message_id=message_id, session_id=session_id, type='4', data=file_name)
    yield wrapped_event(message_id=message_id, session_id=session_id, type='4', data=response_init, )
    for response in sql_obj.Node__generate_sql():
        save_response += response
        yield wrapped_event(message_id=message_id, session_id=session_id, type='4', data=response)

    while True:
        save_response += "\n\n### SQLë¬¸ ì‹¤í–‰ ìœ íš¨ì„± ê²€ì¦\n"
        yield wrapped_event(message_id=message_id, session_id=session_id, type='4', data="\n\n### SQLë¬¸ ì‹¤í–‰ ìœ íš¨ì„± ê²€ì¦\n")

        sql_obj.Node__validate_query()
        if not sql_obj.ERROR:
            logger.info("### SQLë¬¸ í”¼ë“œë°± ìƒì„±")
            save_response += "\n\n### SQLë¬¸ í”¼ë“œë°± ìƒì„±\n"
            yield wrapped_event(message_id=message_id, session_id=session_id, type='4', data="\n\n### SQLë¬¸ í”¼ë“œë°± ìƒì„±\n")
            sql_obj.Node__feedback()
            if sql_obj.RENERATE:
                logger.info("### ë‹µë³€ ì¬ìƒì„±")
                save_response += "### ë‹µë³€ ì¬ìƒì„±\n"
                yield wrapped_event(message_id=message_id, session_id=session_id, type='4', data="### ë‹µë³€ ì¬ìƒì„±\n")
                for response in sql_obj.Node__regenerate():
                    save_response += response
                    yield wrapped_event(message_id=message_id, session_id=session_id, type='4', data=response)
            else:
                save_response += "\n### ğŸ“¢ ë‹µë³€ì´ ì–‘í˜¸í•©ë‹ˆë‹¤. í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œí•©ë‹ˆë‹¤.\n"
                yield wrapped_event(message_id=message_id, session_id=session_id, type='4', data="\n### ğŸ“¢ ë‹µë³€ì´ ì–‘í˜¸í•©ë‹ˆë‹¤. í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œí•©ë‹ˆë‹¤.\n")
                break
        else:
            logger.info("### SQLë¬¸ ì—ëŸ¬ ì²˜ë¦¬\n")
            save_response += "\n### SQLë¬¸ ì—ëŸ¬ ì²˜ë¦¬\n"
            yield wrapped_event(message_id=message_id, session_id=session_id, type='4', data="\n### SQLë¬¸ ì—ëŸ¬ ì²˜ë¦¬")
            for response in sql_obj.Node__handle_error():
                save_response += response
                yield wrapped_event(message_id=message_id, session_id=session_id, type='4', data=response)

    excel_df = sql_obj.Node__get_data_from_db()
    # ì¶”ì¶œëœ ë°ì´í„°ê°€ ì—†ì„ ê²½ìš°
    if len(excel_df) == 0:
        save_response += "\n ### ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n"
        yield wrapped_event(message_id=message_id, session_id=session_id, type='4', data="\n ### ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n")
    else:
        save_response += f"{format_number(len(excel_df))}ê°œì˜ ë°ì´í„°ê°€ ì¡´ì¬í•©ë‹ˆë‹¤.\n\nì•„ë˜ëŠ” ì¶”ì¶œí•œ ë°ì´í„° ëª©ë¡ ì¼ë¶€ì…ë‹ˆë‹¤.\n"
        yield wrapped_event(message_id=message_id, session_id=session_id, type='4', data=f"{format_number(len(excel_df))}ê°œì˜ ë°ì´í„°ê°€ ì¡´ì¬í•©ë‹ˆë‹¤.\n\nì•„ë˜ëŠ” ì¶”ì¶œí•œ ë°ì´í„° ëª©ë¡ ì¼ë¶€ì…ë‹ˆë‹¤.\n")
        # ì—‘ì…€ ì ìš©
        excel_applier.apply_format(excel_df)
        excel_applier.set_data()
        excel_applier.set_time_and_path(datetime.now())
        excel_applier.extract_common_parts()

        # íšŒì‹  ì–‘ì‹ ì—…ë¡œë“œ
        if template_upload == "continue":
            if use_template_cols == "continue":
                save_path = excel_applier.yes_template_with_template_cols()
            # ì¸ê³µì§€ëŠ¥ì´ ìƒì„±í•œ ì»¬ëŸ¼ ì‚¬ìš©
            elif use_template_cols == "cancel":
                save_path = excel_applier.yes_template_with_llm_cols()
        # íšŒì‹  ì–‘ì‹ ë¯¸ì—…ë¡œë“œ
        else:
            save_path = excel_applier.no_template()
        userDB.set_download_fn(session_id, category, save_path)

        check_number = len(excel_df.head(
            2).to_markdown(index=False).split(" "))
        for idx, part in enumerate(excel_df.head(2).to_markdown(index=False).split(" ")):
            if check_number == (idx+1):
                save_response += part
                yield wrapped_event(message_id=message_id, session_id=session_id, type='4', data=part, download=os.path.basename(save_path))
            else:
                save_response += part
                yield wrapped_event(message_id=message_id, session_id=session_id, type='4', data=part)
        # ì²« ì§ˆë¬¸ ì‚¬ìš©ì ì •ë³´ ì´ˆê¸°í™”
        userDB.set_init_input(session_id, '', category)
        conv_history.add_chat(
            {"user": {
                "message_id": f"{message_id}_user",
                "data": input_data,
                "source": [],
                "type": screen_type,
                "plot": "",
                "relevant_query": [],
                "download": ""
            },
                "assistant": {
                "message_id": f"{message_id}_ai",
                "data": save_response,
                "source": [],
                "type": screen_type,
                "plot": "",
                "relevant_query": [],
                "download": os.path.basename(save_path)
            }}
        )


def statistics_chain(
    input_data: str,
    session_id: str,
    userDB: dict,
    extract_info: dict,
    message_id: str,
    screen_type: str,
    file_name: str = ''
):
    category = 'statistics'
    # ëŒ€í™” ì´ë ¥ ë“¤ê³ ì˜¤ê¸°
    conv_history = ConversationHistory(session_id)

    # ì´ˆê¸° ì…ë ¥ ë°ì´í„°
    input_prompt = userDB.get_init_input(session_id, category)
    # í•­êµ¬ì •ë³´, ì‹œê°„ ì •ë³´ ì ê²€ chain
    if input_prompt == input_data:
        input_data = ''
    # í•­êµ¬ì •ë³´, ì‹œê°„ ì •ë³´ ì ê²€ chain
    info_check, response, statistics_info = check_chain(
        input_data, extract_info, userDB, session_id, category)
    response_form = response
    if len(file_name) != 0:
        response_form = [file_name, response]
    # logger.warning(f"response_form :{response_form}")
    if info_check:
        # SQL ìƒì„± chain
        input_prompt = userDB.get_init_input(session_id, category)
        logger.warning(f"input_prompt :{input_prompt}")
        response = sql_chain(
            userDB, session_id, input_data, input_prompt, category,
            statistics_info, extract_info, conv_history, message_id,
            screen_type, file_name
        )
        # user init ì´ˆê¸°í™”
        userDB.set_init(session_id, True, category)
        return response
    else:  # ì •ë³´ë¶€ì¡±
        # í•­êµ¬ì •ë³´, ì‹œê°„ ì •ë³´ ì ê²€ ê²°ê³¼ ë°˜í™˜
        conv_history.add_chat(
            {"user": {
                "message_id": f"{message_id}_user",
                "data": input_data,
                "source": [],
                "type": screen_type,
                "plot": "",
                "relevant_query": [],
                "download": ""
            },
                "assistant": {
                "message_id": f"{message_id}_ai",
                    "data": response,
                    "source": [],
                    "type": screen_type,
                    "plot": "",
                    "relevant_query": [],
                    "download": ""
            }}
        )
        return wrapped_string_generator(response_form, session_id, type=screen_type, message_id=message_id)


def general_answer_chain(
        prompt_state: dict, conv_history: ConversationHistory, session_id: str,
        message_id: str, screen_type: str, userDB: dict, send_data: str
):
    save_response = ''
    category = 'analysis'
    init_input_data = prompt_state["CURRENT"]["MESSAGE"]
    for token in send_data.split():
        yield wrapped_event(message_id=message_id, session_id=session_id, type=screen_type, data=token)
    for response in Chain__generate_general_answer.stream(prompt_state):
        save_response += response.content
        yield wrapped_event(message_id=message_id, session_id=session_id, type=screen_type, data=response.content)
    userDB.set_init_input(session_id, '', category)
    # ai ë‹µë³€ ë“±ë¡
    conv_history.add_chat(
        {"user": {
            "message_id": f"{message_id}_user",
            "data": '',
            "source": [],
            "type": screen_type,
            "plot": "",
            "relevant_query": [],
            "download": ""
        },
            "assistant": {
            "message_id": f"{message_id}_ai",
            "data": save_response,
            "source": [],
            "type": screen_type,
            "plot": "",
            "relevant_query": [],
            "download": ""
        }}
    )


def web_search_and_answer_chain(
        prompt_state: dict, conv_history: ConversationHistory, session_id: str,
        message_id: str, screen_type: str, userDB: dict, send_data: str
):
    category = 'analysis'
    init_input_data = prompt_state["CURRENT"]["MESSAGE"]
    if conv_history.CHATS:
        previous_message = conv_history.CHATS[-2]['content']
        prompt_state['CURRENT']['PREVIOUS_MESSAGE'] = previous_message
    else:
        prompt_state['CURRENT']['PREVIOUS_MESSAGE'] = ""
    # ì´ì „ ì„ íƒ ê²°ê³¼ ë³´ë‚´ê¸°
    for token in send_data.split():
        yield wrapped_event(message_id=message_id, session_id=session_id, type=screen_type, data=token)
    # ê²€ìƒ‰ ìˆ˜í–‰
    query = Chain__generate_search_text.invoke(prompt_state).content.strip('"')
    # logger.info(query)
    documents = get_search_contents(query)
    source = [{"title": i['title'], "href": i["href"]} for i in documents]
    yield wrapped_event(message_id=message_id, session_id=session_id, type='3', source=source)
    context = "# ì°¸ê³ ë‚´ìš©\n" + \
        '\n'.join(
            [f"ì°¸ê³ ë‚´ìš© ({idx+1}) ì œëª©:{i['title']}\nì°¸ê³ ë‚´ìš© ({idx+1}) ë³¸ë¬¸:{i['body']}" for idx, i in enumerate(documents)])
    # logger.info(self.CONTEXT)  # TODO : í–¥í›„ ì°¸ê³  ì¶œì²˜ê°€ ë“¤ì–´ê°€ëŠ” ë¶€ë¬¸
    # ì‚¬ìš©ì ì§ˆë¬¸ ì¬ìˆ˜ì • (ê²€ìƒ‰í•œ ë‚´ìš©ê³¼ ê²€ìƒ‰ì–´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ê¸° ìœ„í•¨)
    prompt_state["CURRENT"]["MESSAGE"] = copy.deepcopy(query)
    # ì»¨í…ìŠ¤íŠ¸ ì§€ì •
    prompt_state["CURRENT"]["CONTEXT"] = context

    # ë‹µë³€ ìƒì„±
    save_response = ''
    for chunk in Chain__generate_answer_with_context.stream(prompt_state):
        # print("\033[38;5;12m" + chunk.content + "\033[0m", end="", flush=True)
        save_response += chunk.content
        yield wrapped_event(message_id=message_id, session_id=session_id, type='3', data=chunk.content)
    # ëŒ€í™” ì €ì¥
    userDB.set_init_input(session_id, '', category)
    conv_history.add_chat(
        {"user": {
            "message_id": f"{message_id}_user",
            "data": '',
            "source": [],
            "type": screen_type,
            "plot": "",
            "relevant_query": [],
            "download": ""
        },
            "assistant": {
            "message_id": f"{message_id}_ai",
            "data": save_response,
            "source": source,
            "type": screen_type,
            "plot": "",
            "relevant_query": [],
            "download": ""
        }}
    )


def analysis_chain(
        userDB: dict, input_data: str, prompt_state: str, category: str,
        extract_info: dict, statistics_info: dict, session_id: str,
        message_id: str, conv_history: dict, screen_type: str):
    user_info = userDB.get_user_info(session_id, category)
    excel_applier = ExcelTemplateApplier(
        copy.deepcopy(prompt_state["CURRENT"]["MESSAGE"]))

    sql_obj = SQLGenerator(
        prompt_state["CURRENT"]["MESSAGE"],
        extract_info,
        excel_applier,
        category)
    # ë°ì´í„° ë² ì´ìŠ¤ë¡œë¶€í„° ë°ì´í„° ì¶”ì¶œ
    sql_obj.STATE = {
        "MESSAGE": prompt_state["CURRENT"]["MESSAGE"],
        "PORT_DATA_LST": extract_info.PORT_NAME_LST,
        "FAC_NAME_LST": extract_info.FAC_NAME_LST,
        "COUNTRY_LIST": extract_info.COUNTRY_NAME_LST
    }
    sql_obj.USE_INFO = statistics_info
    sql_obj.Node__extract_info()

    # ìµœì¢… ì €ì¥ ê°ì²´
    save_response = ''
    relevant_response = ''

    # SQLë¬¸ ìƒì„± chain ë™ì‘
    response_init = '### SQLë¬¸ ìƒì„±\n'
    save_response += response_init
    yield wrapped_event(message_id=message_id, session_id=session_id, type='3', data=response_init)
    for response in sql_obj.Node__generate_sql():
        save_response += response
        yield wrapped_event(message_id=message_id, session_id=session_id, type='3', data=response)

    while True:
        logger.info("### SQLë¬¸ ì‹¤í–‰ ìœ íš¨ì„± ê²€ì¦")
        yield wrapped_event(message_id=message_id, session_id=session_id, type='3', data="### SQLë¬¸ ì‹¤í–‰ ìœ íš¨ì„± ê²€ì¦")
        sql_obj.Node__validate_query()
        if not sql_obj.ERROR:
            logger.info("### SQLë¬¸ í”¼ë“œë°± ìƒì„±")
            yield wrapped_event(message_id=message_id, session_id=session_id, type='3', data="### SQLë¬¸ í”¼ë“œë°± ìƒì„±\n")
            sql_obj.Node__feedback()
            if sql_obj.RENERATE:
                logger.info("### ë‹µë³€ ì¬ìƒì„±")
                yield wrapped_event(message_id=message_id, session_id=session_id, type='3', data="### ë‹µë³€ ì¬ìƒì„±\n")
                for response in sql_obj.Node__regenerate():
                    save_response += response
                    yield wrapped_event(message_id=message_id, session_id=session_id, type='3', data=response)

            else:
                yield wrapped_event(message_id=message_id, session_id=session_id, type='3', data="### ğŸ“¢ ë‹µë³€ì´ ì–‘í˜¸í•©ë‹ˆë‹¤. í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œí•©ë‹ˆë‹¤.\n")
                break
        else:
            logger.info("### SQLë¬¸ ì—ëŸ¬ ì²˜ë¦¬")
            yield wrapped_event(message_id=message_id, session_id=session_id, type='3', data="### SQLë¬¸ ì—ëŸ¬ ì²˜ë¦¬")
            for response in sql_obj.Node__handle_error():
                save_response += response
                yield wrapped_event(message_id=message_id, session_id=session_id, type='3', data=response)

    '''
        Des:
            ë°ì´í„° ë¶„ì„ ìˆ˜í–‰
    '''
    analysis_df = sql_obj.Node__get_data_from_db()
    analysis_df_markdown = analysis_df.to_markdown(index=False)
    # ì»¨í…ìŠ¤íŠ¸ ì§€ì • (1) ë°ì´í„°í”„ë ˆì„ ì •ë³´ ì§€ì •
    prompt_state["CURRENT"]["DATAFRAME"] = analysis_df_markdown
    # ì»¨í…ìŠ¤íŠ¸ ì§€ì • (2) í†µê³„ì •ë³´ ì§€ì •
    try:
        prompt_state["CURRENT"]["STATISTICS"] = analysis_df.groupby(analysis_df["ë…„ë„"]).agg(
            ['mean', 'min', 'max', 'median', 'sum']).drop('ì›”', axis=1).to_markdown()
    except:
        prompt_state["CURRENT"]["STATISTICS"] = ''

    # ë¶„ì„ ìˆ˜í–‰
    for chunk in Chain__generate_analysis.stream(prompt_state):
        save_response += chunk.content
        relevant_response += chunk.content
        yield wrapped_event(message_id=message_id, session_id=session_id, type='3', data=chunk.content)

    # ëŒ€í™” ì €ì¥
    # self.REVISED_ANSWER = f"ì‹¤ì œ ë°ì´í„° : {self.DF_MARKDOWN}\në‹µë³€ : {self.ANSWER}"
    # self.CONV_OBJ.add_chat({"user": self.SQLOBJ.MESSAGE,
    #                         "assistant": self.REVISED_ANSWER})

    '''
        Des:
            ì‹œê°í™” ìˆ˜í–‰
    '''
    # ì‹œê°í™”
    if check_yes(Chain__check_plot.invoke(prompt_state).content) == "YES":
        logger.info("### ì‹œê°í™” ê²°ê³¼ ìƒì„±")
        save_response += '\n### ì‹œê°í™” ê²°ê³¼ ìƒì„±\n\n'
        yield wrapped_event(message_id=message_id, session_id=session_id, type='3', data="\n### ì‹œê°í™” ê²°ê³¼ ìƒì„±\n\n")
        # plotly
        try:
            content = ''
            PLOTLY_ERROR_HANDLER = ''
            while True:
                prompt_state["CURRENT"]["PLOTLY_ERROR_HANDLER"] = PLOTLY_ERROR_HANDLER
                gen_code = ""
                for chunk in Chain__generate_plotly.stream(prompt_state):
                    # print("\033[38;5;12m" + chunk.content +
                    #       "\033[0m", end="", flush=True)
                    gen_code += chunk.content
                    save_response += chunk.content
                    yield wrapped_event(message_id=message_id, session_id=session_id, type='3', data=chunk.content)

                extract_gen_code = extract_python_plotly_code(gen_code)
                try:
                    global_vars = {"DF": analysis_df}
                    local_vars = {}
                    exec(extract_gen_code, global_vars, local_vars)
                    break
                except Exception as error:
                    logger.warning("ìƒì„±ëœ ì‹œê°í™” ì½”ë“œì— ì˜¤ë¥˜ê°€ ìˆìŠµë‹ˆë‹¤. ì˜¤ë¥˜ ë‚´ìš©ì„ ì°¸ê³ í•´ì„œ ì¬ìƒì„±í•©ë‹ˆë‹¤.")
                    PLOTLY_ERROR_HANDLER = f"\nì´ì „ ì½”ë“œ ì‹¤í–‰ì‹œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\nì´ì „ ì½”ë“œ : {extract_gen_code}\n\nì˜¤ë¥˜ ë‚´ìš© : {str(error)}\n\nì˜¤ë¥˜ ë‚´ìš©ì„ ì°¸ê³ í•˜ì„¸ìš”."
                    save_response += "\nìƒì„±ëœ ì‹œê°í™” ì½”ë“œì— ì˜¤ë¥˜ê°€ ìˆìŠµë‹ˆë‹¤. ì˜¤ë¥˜ ë‚´ìš©ì„ ì°¸ê³ í•´ì„œ ì¬ìƒì„±í•©ë‹ˆë‹¤.\n"
                    yield wrapped_event(message_id=message_id, session_id=session_id, type='3', data="\nìƒì„±ëœ ì‹œê°í™” ì½”ë“œì— ì˜¤ë¥˜ê°€ ìˆìŠµë‹ˆë‹¤. ì˜¤ë¥˜ ë‚´ìš©ì„ ì°¸ê³ í•´ì„œ ì¬ìƒì„±í•©ë‹ˆë‹¤.\n")

            fig = local_vars.get('fig')
            from plotly import io as pio
            content = pio.to_json(fig, validate=True)
            yield wrapped_event(message_id=message_id, session_id=session_id, type='3', plot=content)

        except:
            logger.warning("### ì‹œê°í™”í•˜ê¸°ì— ë°ì´í„°ê°€ ë¶ˆì¶©ë¶„í•©ë‹ˆë‹¤. (ë™ì ) ì‹œê°í™” ì œì™¸í•©ë‹ˆë‹¤.")
            save_response += "\n### ì‹œê°í™”í•˜ê¸°ì— ë°ì´í„°ê°€ ë¶ˆì¶©ë¶„í•©ë‹ˆë‹¤. (ë™ì ) ì‹œê°í™” ì œì™¸í•©ë‹ˆë‹¤.\n"
            yield wrapped_event(message_id=message_id, session_id=session_id, type='3', data="\n### ì‹œê°í™”í•˜ê¸°ì— ë°ì´í„°ê°€ ë¶ˆì¶©ë¶„í•©ë‹ˆë‹¤. (ë™ì ) ì‹œê°í™” ì œì™¸í•©ë‹ˆë‹¤.\n")

    '''
        Des:
            ê´€ë ¨/ì¶”ì²œ ì§ˆë¬¸ ìƒì„±
    '''
    # ê´€ë ¨ ì§ˆë¬¸ ìƒì„± (ê²€ìƒ‰ ê¸°ë°˜ ì´ì „ ëŒ€í™” ì°¸ê³ )
    if user_info['btn1'] == "cancel":
        try:
            relevant_queries = Chain__relevant_query_with_search.invoke({"MESSAGE": prompt_state["CURRENT"]["MESSAGE"],
                                                                        "ANSWER": relevant_response}).content
        except:
            relevant_queries = []
    # ê´€ë ¨ ì§ˆë¬¸ ìƒì„± (ë°ì´í„°ë² ì´ìŠ¤ ê¸°ë°˜ ì´ì „ ëŒ€í™” ì°¸ê³ )
    else:
        try:
            relevant_queries = Chain__relevant_query_with_database.invoke({"MESSAGE": prompt_state["CURRENT"]["MESSAGE"],
                                                                           "ANSWER": relevant_response}).content
        except:
            relevant_queries = []
    yield wrapped_event(message_id=message_id, session_id=session_id, type='3', plot=content, relevant_query=relevant_queries)
    userDB.set_init_input(session_id, '', category)
    conv_history.add_predict_chat(
        {"user": {
            "message_id": f"{message_id}_user",
            "data": input_data,
        },
            "assistant": {
            "message_id": f"{message_id}_ai",
            "data": relevant_response,
        }}
    )
    conv_history.add_chat(
        {"user": {
            "message_id": f"{message_id}_user",
            "data": input_data,
            "source": [],
            "type": screen_type,
            "plot": "",
            "relevant_query": [],
            "download": ""
        },
            "assistant": {
            "message_id": f"{message_id}_ai",
            "data": save_response,
            "source": [],
            "type": screen_type,
            "plot": content,
            "relevant_query": relevant_queries,
            "download": ""
        }}
    )
    # conv_history.add_chat(
    #     {"user": input_data,
    #      "assistant": save_response}
    # )


def harbor_chain(
    input_data: str,
    session_id: str,
    userDB: dict,
    extract_info: dict,
    message_id: str,
    screen_type: str,
    send_data: str = ''
):
    '''
    í•­ë§Œë°ì´í„°ë¶„ì„ìš© LLM ì¶”ë¡  í•¨ìˆ˜
    args:
        input_data : ì‚¬ìš©ì ì…ë ¥ë°ì´í„°
        session_id : ëŒ€í™”ì°½ ì•„ì´ë””
    '''
    category = 'analysis'
    # ì‚¬ìš©ì ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    user_info = userDB.get_user_info(session_id, category)

    use_database = user_info['btn1']
    use_search = user_info['btn2']
    # ì´ì „ ëŒ€í™”ë“¤ê³ ì˜¤ê¸°
    conv_history = ConversationHistory(session_id)
    conv_history.get_history_chats()
    conv_history.get_histotry_format_prompt()
    # í˜„ì‹œì  ì…ë ¥ í…ìŠ¤íŠ¸ : input_data
    logger.warning(f"conv_history.HISTORY {conv_history.HISTORY}")
    prompt_state = {
        "CURRENT": {"MESSAGE": input_data},
        "HISTORY": conv_history.HISTORY
    }
    # done!!
    if not use_database:
        if not use_search:  # ì¼ë°˜ ëŒ€í™”
            logger.warning(f"ì¼ë°˜ ëŒ€í™”")
            userDB.set_init(session_id, True, category)
            response = general_answer_chain(
                prompt_state, conv_history, session_id, message_id, screen_type, userDB, send_data)
            return response
        else:  # ì›¹ì •ë³´ í™œìš©
            logger.warning(f"ì›¹ì •ë³´ í™œìš©")
            userDB.set_init(session_id, True, category)
            response = web_search_and_answer_chain(
                prompt_state, conv_history, session_id, message_id, screen_type, userDB, send_data)
            return response
    else:  # ë‚´ë¶€ DB ì‚¬ìš©
        logger.warning(f"ë‚´ë¶€ DB ì‚¬ìš©")
        # ì‚¬ìš©ì ì •ë³´ì— ê¸°ë¡ëœ ì²« ì§ˆë¬¸ + í•­êµ¬ + ì‹œê°„ ì •ë³´
        input_prompt = userDB.get_init_input(session_id, category)
        # í•­êµ¬ì •ë³´, ì‹œê°„ ì •ë³´ ì ê²€ chain
        if input_prompt == input_data:
            input_data = ''
        info_check, response, analysis_info = check_chain(
            input_data, extract_info, userDB, session_id, category)
        if info_check:
            # ì²« ì§ˆë¬¸ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ ìˆ˜ì •
            prompt_state["CURRENT"]["MESSAGE"] = input_prompt
            # analysis ìƒì„± chain
            logger.warning(f"analysis ìƒì„± chain")
            userDB.set_init(session_id, True, category)
            response = analysis_chain(
                userDB, input_data, prompt_state, category, extract_info,
                analysis_info, session_id, message_id, conv_history, screen_type
            )
            return response
        else:  # ì •ë³´ë¶€ì¡±
            # í•­êµ¬ì •ë³´, ì‹œê°„ ì •ë³´ ì ê²€ ê²°ê³¼ ë°˜í™˜
            logger.warning(f"í•­êµ¬ì •ë³´, ì‹œê°„ ì •ë³´ ì ê²€ ê²°ê³¼ ë°˜í™˜")
            conv_history.add_chat(
                {"user": {
                    "message_id": f"{message_id}_user",
                    "data": input_data,
                    "source": [],
                    "type": screen_type,
                    "plot": "",
                    "relevant_query": [],
                    "download": ""
                },
                    "assistant": {
                    "message_id": f"{message_id}_ai",
                    "data": response,
                    "source": [],
                    "type": screen_type,
                    "plot": "",
                    "relevant_query": [],
                    "download": ""
                }}
            )
        return wrapped_string_generator(response, session_id, type=screen_type, message_id=message_id)
