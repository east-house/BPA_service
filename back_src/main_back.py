from utils.text_to_sql import *
from modules.chain import *
from modules.service import statistics_chain, harbor_chain
from fastapi.responses import StreamingResponse, JSONResponse
from fastapi import FastAPI, HTTPException, Request, status, Body, Header, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from concurrent.futures import ThreadPoolExecutor
from starlette.responses import FileResponse
from utils.util import *
from utils.history import ConversationHistory
from loguru import logger
from typing import List
from jose import jwt

import argparse
import asyncio
import uvicorn
import uuid
import os

from utils.dummy_user import UserModule

from utils.sql_to_excel import ExcelTemplateApplier
from modules.node import SQLGenerator

userDB = UserModule()
extract_info = ExtractInfo()
extract_info.load_name_lst()

session_id = userDB.gen_session_id()


def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument("--port", type=int, default=80)
    parser.add_argument("--host", type=str, default="0.0.0.0")
    parser.add_argument("--workers", type=int, default=3)
    args = parser.parse_args()
    return args


args = parse_args()
executor = ThreadPoolExecutor()
app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ëª¨ë“  origin í—ˆìš©. í•„ìš”ì— ë”°ë¼ ë³€ê²½ ê°€ëŠ¥
    allow_credentials=True,
    allow_methods=["*"],  # ëª¨ë“  HTTP ë©”ì†Œë“œ í—ˆìš©
    allow_headers=["*"],  # ëª¨ë“  í—¤ë” í—ˆìš©
)
app.mount("/exports", StaticFiles(directory="exports"), name="exports")
app.mount("/imports", StaticFiles(directory="imports"), name="imports")
# app.mount("/data", StaticFiles(directory="data"), name="data")


@app.exception_handler(HTTPException)
def http_exception_handler(request, exc):
    return JSONResponse(
        content={
            "state": exc.status_code,
            "result": "",
            "message": exc.detail
        }
    )


@app.middleware("http")
async def add_executor_middleware(request: Request, call_next):
    '''
    reqeustë¥¼ ë°›ì•„ì„œ  í”„ë¡œì„¸ìŠ¤ë¥¼ ë¹„ë™ê¸° ì²˜ë¦¬í•¨ìˆ˜ë¡œ ì „ë‹¬
    '''
    user_token = request.headers.get('user-token')
    if user_token != None:  # ë¹„ë¡œê·¸ì¸ ì‚¬ìš©ì
        try:
            token_type, token = user_token.split()
            if token_type != "Bearer":
                raise HTTPException(
                    status_code=status.HTTP_403_FORBIDDEN, detail="The authentication method is incorrect.")
            user_data = jwt.decode(token, "default", algorithms=["HS256"])
        except Exception as e:
            logger.warning(f"error message : {e}")
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN, detail="Not authenticated")
        request.state.user_data = user_data
    request.state.executor = executor
    response = await call_next(request)
    return response


async def run_task_block(func, *args, **kwargs):
    '''
    ë¯¸ë“¤ì›¨ì–´ë¥¼ í†µí™”í•´ ì‹¤í–‰ ìš”ì²­ì´ëœ í•¨ìˆ˜ë¥¼ threadë¡œ ë¶„ì‚°í•˜ì—¬ ë¹„ë™ê¸° ì²˜ë¦¬
    í•¨ìˆ˜ ì‘ì„± ì˜ˆì‹œ
    @app.get("/task1/{seconds}")
    async def task1(seconds: int):
        result = await run_blocking_task([ì²˜ë¦¬í•  í•¨ìˆ˜], [í•¨ìˆ˜ì— ì‚¬ìš©ë˜ëŠ” ë³€ìˆ˜1], [í•¨ìˆ˜ì— ì‚¬ìš©ë˜ëŠ” ë³€ìˆ˜2])
        return {"result": result}
    '''
    loop = asyncio.get_event_loop()
    result = await loop.run_in_executor(executor, func, *args, **kwargs)
    return result


@app.post("/testchain")
async def _statistics_chain(
    # request: Request,
    input_data: str = Body(''),
    session_id: str = Body('tmp_session_id')
):
    category = 'statistics'
    message_id = str(uuid.uuid4())[:6]
    conv_history = ConversationHistory(session_id)
    # ì‚¬ìš©ì ë¬¸ì ìˆëŠ”ì§€ ì—¬ë¶€ í™•ì¸
    if len(session_id.strip()) == 0:
        session_id = userDB.gen_session_id()
    # DBì— ì‚¬ìš©ì session_id ìˆëŠ”ì§€ í™•ì¸
    elif userDB.check_session_id(session_id):
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST, detail="session_id is not exist..")
    # ì´ˆê¸° ì§ˆë¬¸ ì‚¬ìš©ì ì •ë³´ì— ì €ì¥
    userDB.set_init_input(session_id, input_data, category)

    screen_type = '4'
    # í†µê³„ìš© LLM chain
    response = statistics_chain(
        input_data, session_id, userDB, extract_info, message_id)
    return StreamingResponse(response)


@app.post("/test_chain_analysis")
async def harbor_llm(
    request: Request,
    input_data: str = Body(''),
    session_id: str = Body('tmp_session_id')
) -> dict:
    '''
    í•­ë§Œë°ì´í„° ë¶„ì„ llm ì¶”ë¡  
    '''
    category = 'analysis'
    message_id = str(uuid.uuid4())[:6]
    conv_history = ConversationHistory(session_id)
    # ì‚¬ìš©ì ë¬¸ì ìˆëŠ”ì§€ ì—¬ë¶€ í™•ì¸
    if len(session_id.strip()) == 0:
        session_id = userDB.gen_session_id()
    # DBì— ì‚¬ìš©ì session_id ìˆëŠ”ì§€ í™•ì¸
    elif userDB.check_session_id(session_id):
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST, detail="session_id is not exist..")
    # ì´ˆê¸° ì§ˆë¬¸ ì‚¬ìš©ì ì •ë³´ì— ì €ì¥
    userDB.set_init_input(session_id, input_data, category)
    # ìœ ì € ì •ë³´ ë“¤ê³ ì˜´
    user_info = userDB.get_user_info(session_id, category)
    screen_type = '3'
    # í†µê³„ìš© LLM chain
    response = harbor_chain(input_data, session_id,
                            userDB, extract_info, message_id)
    return StreamingResponse(response)

    ########################


# def general_answer_chain(prompt_state: dict, conv_history: ConversationHistory):
#     save_response = ''
#     for response in Chain__generate_general_answer.stream(prompt_state):
#         print("\033[38;5;12m" + response.content +
#               "\033[0m", end="", flush=True)
#         save_response += response.content
#         yield response.content
#     # ai ë‹µë³€ ë“±ë¡
#     conv_history.add_chat(
#         {"user": prompt_state['CURRENT']['MESSAGE'],
#          "assistant": save_response}
#     )


# def web_search_and_answer_chain(prompt_state: dict, conv_history: ConversationHistory):
#     if conv_history.CHATS:
#         previous_message = conv_history.CHATS[-2]['content']
#         prompt_state['CURRENT']['PREVIOUS_MESSAGE'] = previous_message
#     else:
#         prompt_state['CURRENT']['PREVIOUS_MESSAGE'] = ""
#     # ê²€ìƒ‰ ìˆ˜í–‰
#     query = Chain__generate_search_text.invoke(prompt_state).content.strip('"')
#     # logger.info(query)
#     documents = get_search_contents(query)
#     source = [{"title": i['title'], "href": i["href"]} for i in documents]
#     context = "# ì°¸ê³ ë‚´ìš©\n" + \
#         '\n'.join(
#             [f"ì°¸ê³ ë‚´ìš© ({idx+1}) ì œëª©:{i['title']}\nì°¸ê³ ë‚´ìš© ({idx+1}) ë³¸ë¬¸:{i['body']}" for idx, i in enumerate(documents)])
#     # logger.info(self.CONTEXT)  # TODO : í–¥í›„ ì°¸ê³  ì¶œì²˜ê°€ ë“¤ì–´ê°€ëŠ” ë¶€ë¬¸
#     # ì‚¬ìš©ì ì§ˆë¬¸ ì¬ìˆ˜ì • (ê²€ìƒ‰í•œ ë‚´ìš©ê³¼ ê²€ìƒ‰ì–´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ê¸° ìœ„í•¨)
#     prompt_state["CURRENT"]["MESSAGE"] = copy.deepcopy(query)

#     # ì»¨í…ìŠ¤íŠ¸ ì§€ì •
#     prompt_state["CURRENT"]["CONTEXT"] = context

#     # ë‹µë³€ ìƒì„±
#     save_response = ''
#     for chunk in Chain__generate_answer_with_context.stream(prompt_state):
#         print("\033[38;5;12m" + chunk.content + "\033[0m", end="", flush=True)
#         save_response += chunk.content
#         yield chunk.content
#     # ëŒ€í™” ì €ì¥
#     conv_history.add_chat({"user": query,
#                            "assistant": save_response})


# def _analysis_chain(user_info: str, prompt_state: str, category: str, statistics_info: dict, conv_history: ConversationHistory):
#     excel_applier = ExcelTemplateApplier(
#         copy.deepcopy(prompt_state["CURRENT"]["MESSAGE"]))

#     sql_obj = SQLGenerator(
#         prompt_state["CURRENT"]["MESSAGE"],
#         extract_info,
#         excel_applier,
#         category)
#     # ë°ì´í„° ë² ì´ìŠ¤ë¡œë¶€í„° ë°ì´í„° ì¶”ì¶œ
#     sql_obj.STATE = {
#         "MESSAGE": prompt_state["CURRENT"]["MESSAGE"],
#         "PORT_DATA_LST": extract_info.PORT_NAME_LST,
#         "FAC_NAME_LST": extract_info.FAC_NAME_LST,
#         "COUNTRY_LIST": extract_info.COUNTRY_NAME_LST
#     }
#     sql_obj.USE_INFO = statistics_info
#     sql_obj.Node__extract_info()

#     # ìµœì¢… ì €ì¥ ê°ì²´
#     save_response = ''
#     relevant_response = ''
#     # SQLë¬¸ ìƒì„± chain ë™ì‘
#     response_init = '### SQLë¬¸ ìƒì„±\n'
#     yield response_init
#     for response in sql_obj.Node__generate_sql():
#         save_response += response
#         yield response

#     while True:
#         logger.info("### SQLë¬¸ ì‹¤í–‰ ìœ íš¨ì„± ê²€ì¦")
#         yield "### SQLë¬¸ ì‹¤í–‰ ìœ íš¨ì„± ê²€ì¦\n"
#         sql_obj.Node__validate_query()
#         if not sql_obj.ERROR:
#             logger.info("### SQLë¬¸ í”¼ë“œë°± ìƒì„±")
#             yield "### SQLë¬¸ í”¼ë“œë°± ìƒì„±\n"
#             sql_obj.Node__feedback()
#             if sql_obj.RENERATE:
#                 logger.info("### ë‹µë³€ ì¬ìƒì„±")
#                 yield "### ë‹µë³€ ì¬ìƒì„±\n"
#                 for response in sql_obj.Node__regenerate():
#                     save_response += response
#                     yield response
#             else:
#                 yield "### ğŸ“¢ ë‹µë³€ì´ ì–‘í˜¸í•©ë‹ˆë‹¤. í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œí•©ë‹ˆë‹¤.\n"
#                 break
#         else:
#             logger.info("### SQLë¬¸ ì—ëŸ¬ ì²˜ë¦¬")
#             yield "### SQLë¬¸ ì—ëŸ¬ ì²˜ë¦¬"
#             for response in sql_obj.Node__handle_error():
#                 save_response += response
#                 yield response

#     '''
#         Des:
#             ë°ì´í„° ë¶„ì„ ìˆ˜í–‰
#     '''
#     analysis_df = sql_obj.Node__get_data_from_db()

#     analysis_df_markdown = analysis_df.to_markdown(index=False)

#     # ì»¨í…ìŠ¤íŠ¸ ì§€ì • (1) ë°ì´í„°í”„ë ˆì„ ì •ë³´ ì§€ì •
#     prompt_state["CURRENT"]["DATAFRAME"] = analysis_df_markdown

#     # ì»¨í…ìŠ¤íŠ¸ ì§€ì • (2) í†µê³„ì •ë³´ ì§€ì •
#     try:
#         prompt_state["CURRENT"]["STATISTICS"] = analysis_df.groupby(analysis_df["ë…„ë„"]).agg(
#             ['mean', 'min', 'max', 'median', 'sum']).drop('ì›”', axis=1).to_markdown()
#     except:
#         prompt_state["CURRENT"]["STATISTICS"] = ''

#     # ë¶„ì„ ìˆ˜í–‰

#     for chunk in Chain__generate_analysis.stream(prompt_state):
#         save_response += chunk.content
#         relevant_response += chunk.content
#         yield chunk.content

#     # ëŒ€í™” ì €ì¥
#     # self.REVISED_ANSWER = f"ì‹¤ì œ ë°ì´í„° : {self.DF_MARKDOWN}\në‹µë³€ : {self.ANSWER}"
#     # self.CONV_OBJ.add_chat({"user": self.SQLOBJ.MESSAGE,
#     #                         "assistant": self.REVISED_ANSWER})

#     '''
#         Des:
#             ì‹œê°í™” ìˆ˜í–‰
#     '''
#     # ì‹œê°í™”
#     if check_yes(Chain__check_plot.invoke(prompt_state).content) == "YES":
#         logger.info("### ì‹œê°í™” ê²°ê³¼ ìƒì„±")
#         yield "### ì‹œê°í™” ê²°ê³¼ ìƒì„±\n\n"
#         # plotly
#         try:
#             PLOTLY_ERROR_HANDLER = ''
#             while True:
#                 prompt_state["CURRENT"]["PLOTLY_ERROR_HANDLER"] = PLOTLY_ERROR_HANDLER
#                 gen_code = ""
#                 for chunk in Chain__generate_plotly.stream(prompt_state):
#                     # print("\033[38;5;12m" + chunk.content +
#                     #       "\033[0m", end="", flush=True)
#                     gen_code += chunk.content
#                     yield chunk.content
#                 extract_gen_code = extract_python_plotly_code(gen_code)
#                 try:
#                     global_vars = {"DF": analysis_df}
#                     local_vars = {}
#                     exec(extract_gen_code, global_vars, local_vars)
#                     break
#                 except Exception as error:
#                     logger.warning("ìƒì„±ëœ ì‹œê°í™” ì½”ë“œì— ì˜¤ë¥˜ê°€ ìˆìŠµë‹ˆë‹¤. ì˜¤ë¥˜ ë‚´ìš©ì„ ì°¸ê³ í•´ì„œ ì¬ìƒì„±í•©ë‹ˆë‹¤.")
#                     PLOTLY_ERROR_HANDLER = f"\nì´ì „ ì½”ë“œ ì‹¤í–‰ì‹œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\nì´ì „ ì½”ë“œ : {extract_gen_code}\n\nì˜¤ë¥˜ ë‚´ìš© : {str(error)}\n\nì˜¤ë¥˜ ë‚´ìš©ì„ ì°¸ê³ í•˜ì„¸ìš”."
#                     yield f"\nìƒì„±ëœ ì‹œê°í™” ì½”ë“œì— ì˜¤ë¥˜ê°€ ìˆìŠµë‹ˆë‹¤. ì˜¤ë¥˜ ë‚´ìš©ì„ ì°¸ê³ í•´ì„œ ì¬ìƒì„±í•©ë‹ˆë‹¤.\n"

#             fig = local_vars.get('fig')
#             from plotly import io as pio
#             content = pio.to_json(fig, validate=True)
#             yield content

#         except:
#             logger.warning("### ì‹œê°í™”í•˜ê¸°ì— ë°ì´í„°ê°€ ë¶ˆì¶©ë¶„í•©ë‹ˆë‹¤. (ë™ì ) ì‹œê°í™” ì œì™¸í•©ë‹ˆë‹¤.")

#     '''
#         Des:
#             ê´€ë ¨/ì¶”ì²œ ì§ˆë¬¸ ìƒì„±
#     '''
#     # ê´€ë ¨ ì§ˆë¬¸ ìƒì„± (ê²€ìƒ‰ ê¸°ë°˜ ì´ì „ ëŒ€í™” ì°¸ê³ )
#     if user_info['btn1'] == "cancel":
#         relevant_queries = Chain__relevant_query_with_search.invoke({"MESSAGE": prompt_state["CURRENT"]["MESSAGE"],
#                                                                      "ANSWER": relevant_response}).content

#     # ê´€ë ¨ ì§ˆë¬¸ ìƒì„± (ë°ì´í„°ë² ì´ìŠ¤ ê¸°ë°˜ ì´ì „ ëŒ€í™” ì°¸ê³ )
#     else:
#         relevant_queries = Chain__relevant_query_with_database.invoke({"MESSAGE": prompt_state["CURRENT"]["MESSAGE"],
#                                                                        "ANSWER": relevant_response}).content
#     yield relevant_queries


@ app.post('/load_chat')
async def load_chat(
    request: Request,
    session_id: str = Body('tmp_session_id'),
) -> dict:
    '''
    ìƒˆë¡œê³ ì¹¨ ë° ë’¤ë¡œê°€ê¸° ì‚¬ìš©ì‹œ í˜„ì¬ ëŒ€í™” ë¶ˆëŸ¬ì˜¤ê¸°\n
    session_id : ëŒ€í™”ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ê°ì²´ key ê°’
    '''
    category = "statistics"
    conv_history = ConversationHistory(session_id)
    previous_chats = conv_history.get_all_chats()
    chat_list = []
    for pre_chat in previous_chats:
        if not (pre_chat['user'].startswith("Selected") or pre_chat['user'].startswith("File")):
            if pre_chat['user'] != '':
                chat_list.append({
                    'id': 'user',
                    'data': pre_chat['user'],
                    'session_id': session_id
                })
            if pre_chat['assistant'] != '':
                chat_list.append({
                    'id': 'ai',
                    'data': pre_chat['assistant'],
                    'session_id': session_id
                })
    return JSONResponse(
        content={
            "state": status.HTTP_200_OK,
            "result": chat_list,
            "message": "success"
        }
    )


@app.post("/statistics_btn_one")
async def statistics_btn_one(
    request: Request,
    session_id: str = Body('tmp_session_id'),
    click_value: str = Body('')
) -> dict:
    '''
    1) íšŒì‹ ì–‘ì‹ ì—…ë¡œë“œ 2) íšŒì‹ ì–‘ì‹ ë¯¸ì—…ë¡œë“œ ì¤‘ì—ì„œ ì„ íƒ
    í†µê³„ ë¶€ë¶„ì—ì„œ ì‚¬ìš©ë˜ëŠ” ì²«ë²ˆì§¸ ë²„íŠ¼ 
    '''
    category = 'statistics'
    conv_history = ConversationHistory(session_id)
    response = userDB.set_btn_one(session_id, click_value, category)
    userDB.set_init(session_id, False, category)
    # íšŒì‹ ì–‘ì‹ ì—…ë¡œë“œ
    pre_text = f'Selected : {click_value}'

    message_id = str(uuid.uuid4())[:6]
    # debug part
    user_info = userDB.get_user_info(session_id, category)
    logger.warning(f"user_info : {user_info}")
    if response:
        conv_history.add_chat(
            {"user": '',
             "assistant": pre_text}
        )
        screen_type = '2'
        data = f"{pre_text}\n ì–‘ì‹ì— ê¸°ì¬ëœ ì»¬ëŸ¼ëª…ë“¤ì„ ë™ì¼í•˜ê²Œ ì‚¬ìš©í•˜ì‹œê² ìŠµë‹ˆê¹Œ?"
        return StreamingResponse(wrapped_string_generator(data, session_id, screen_type, message_id))
    else:
        screen_type = '4'
        # í†µê³„ìš© LLM chain
        input_data = userDB.get_init_input(session_id, category)
        response = statistics_chain(
            input_data, session_id, userDB, extract_info, message_id)
        return StreamingResponse(response)


@app.post("/statistics_btn_two")
async def statistics_btn_two(
    request: Request,
    session_id: str = Body('tmp_session_id'),
    click_value: str = Body('')
) -> dict:
    '''
    1) íšŒì‹ ì–‘ì‹ ì»¬ëŸ¼ ì‚¬ìš© 2) ì¸ê³µì§€ëŠ¥ ìƒì„± ì»¬ëŸ¼ ì‚¬ìš©
    í†µê³„ ë¶€ë¶„ì—ì„œ ì‚¬ìš©ë˜ëŠ” ë‘ë²ˆì§¸ ë²„íŠ¼ 
    '''
    category = 'statistics'
    response = userDB.set_btn_two(session_id, click_value, category)
    message_id = str(uuid.uuid4())[:6]
    conv_history = ConversationHistory(session_id)
    chat_history = conv_history.get_all_chats()
    pre_data = chat_history[-1]['assistant']
    if response:
        screen_type = '3'
        data = f'Selected : {click_value}'
        send_data = f"{pre_data}\n\n{data}"
        conv_history.add_chat(
            {"user": '',
             "assistant": data}
        )
        # user_info = userDB.get_user_info(session_id, category)
        # logger.warning(f"user_info : {user_info}")
        return StreamingResponse(wrapped_string_generator(send_data, session_id, screen_type, message_id))
    else:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST, detail="Unable to save btn data to user information..")


@app.post("/upload_file")
async def upload_file(
    request: Request,
    files: List[UploadFile] = File(default=[]),
    session_id: str = Body('tmp_session_id')
) -> dict:
    '''
    # íŒŒì¼ ì—…ë¡œë“œ
    ë‹¨ìˆœ íŒŒì¼ ì—…ë¡œë“œ xlsx í™•ì¥ìë§Œ ê°€ëŠ¥í•˜ê³  íŒŒì¼ ê°¯ìˆ˜ëŠ” 1ê°œ
    '''
    category = 'statistics'
    message_id = str(uuid.uuid4())[:6]
    conv_history = ConversationHistory(session_id)
    # íŒŒì¼ ê°¯ìˆ˜ ì²´í¬
    if len(files) > 1:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST, detail="Over file number..")
    # íŒŒì¼ í™•ì¥ì ì ê²€
    for fi in files:
        xlsx_path = check_save_xlsx(fi)
    send_name = os.path.basename(xlsx_path)
    conv_history.add_chat(
        {"user": '',
         "assistant": f'File: {send_name}'}
    )
    response = userDB.set_filename(session_id, xlsx_path)
    if response:
        screen_type = '4'
        # í†µê³„ìš© LLM chain
        input_data = userDB.get_init_input(session_id, category)
        response = statistics_chain(
            input_data, session_id, userDB, extract_info, message_id, file_name=send_name)
        return StreamingResponse(response)
    else:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST, detail="Unable to save file information to user information..")


@app.post("/download_file")
async def download_file(
    request: Request,
    session_id: str = Body('tmp_session_id')
) -> dict:
    '''
    # íŒŒì¼ ë‹¤ìš´ë¡œë“œ
    '''
    category = 'statistics'

    try:
        file_path = "exports/BPA_tmp_v1.xlsx"
        # fn = dummy_user['save_filename']
        # file_path = f"exports/{fn}"
        return JSONResponse(
            content={
                "state": status.HTTP_200_OK,
                "result": f'/{file_path}',
                "message": "success"
            }
        )
    except:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST, detail="xlsx file is not exist..")


@app.post("/statistics_llm")
async def statistics_llm(
    request: Request,
    input_data: str = Body(''),
    session_id: str = Body('tmp_session_id'),
) -> dict:
    category = 'statistics'
    message_id = str(uuid.uuid4())[:6]
    conv_history = ConversationHistory(session_id)
    # ì‚¬ìš©ì ë¬¸ì ìˆëŠ”ì§€ ì—¬ë¶€ í™•ì¸
    if len(session_id.strip()) == 0:
        session_id = userDB.gen_session_id()
    # DBì— ì‚¬ìš©ì session_id ìˆëŠ”ì§€ í™•ì¸
    elif userDB.check_session_id(session_id):
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST, detail="session_id is not exist..")
    # ì´ˆê¸° ì§ˆë¬¸ ì‚¬ìš©ì ì •ë³´ì— ì €ì¥
    userDB.set_init_input(session_id, input_data, category)
    # ìœ ì € ì •ë³´ ë“¤ê³ ì˜´
    user_info = userDB.get_user_info(session_id, category)
    if user_info['init']:  # ì´ˆê¸° ëŒ€í™” ì‹œì‘
        screen_type = '1'
        data = "íšŒì‹  ì–‘ì‹ ì—…ë¡œë“œë¥¼ í•˜ì‹œê² ìŠµë‹ˆê¹Œ?"
        conv_history.add_chat(
            {"user": input_data,
             "assistant": ''}
        )
        return StreamingResponse(wrapped_string_generator(data, session_id, screen_type, message_id))
    else:  # í†µê³„ìš© LLMì„ ì´ìš©í•œ ëŒ€í™”
        screen_type = '4'
        # í†µê³„ìš© LLM chain
        response = statistics_chain(
            input_data, session_id, userDB, extract_info, message_id)
        return StreamingResponse(response)


@app.post("/harbor_btn_one")
async def harbor_btn_one(
    request: Request,
    click_value: str = Body(''),
    session_id: str = Body('')
) -> dict:
    '''
    í•­ë§Œë°ì´í„°ë¶„ì„ ë°©ë²• ì„ íƒ ë²„íŠ¼1
    '''
    category = 'analysis'
    response = userDB.set_btn_one(session_id, click_value, category)
    pre_text = f'Selected : {click_value}'
    if response:
        screen_type = '3'
        data = f"{pre_text}\në”ë¯¸ë°ì´í„° í…ìŠ¤íŠ¸..."
        return JSONResponse(
            content={
                "state": status.HTTP_200_OK,
                "result": {
                    "session_id": session_id,
                    "type": screen_type,
                    "source": [],
                    "data": data,
                    "plot": "",
                    "relevant_query": "",
                },
                "message": "success"
            }
        )
    else:
        screen_type = '2'
        data = f"{pre_text}\n ì›¹ê²€ìƒ‰ ì •ë³´ë¥¼ ì‚¬ìš©í• ê¹Œìš”?"
        return JSONResponse(
            content={
                "state": status.HTTP_200_OK,
                "result": {
                    "session_id": session_id,
                    "type": screen_type,
                    "source": [],
                    "data": data,
                    "plot": "",
                    "relevant_query": "",
                },
                "message": "success"
            }
        )


@app.post("/harbor_btn_two")
async def harbor_btn_two(
    request: Request,
    click_value: str = Body(''),
    session_id: str = Body('')
) -> dict:
    '''
    í•­ë§Œë°ì´í„°ë¶„ì„ ë°©ë²• ì„ íƒ ë²„íŠ¼2
    '''
    category = 'analysis'
    response = userDB.set_btn_one(session_id, click_value, category)

    screen_type = '3'
    data = f'Selected : {click_value}'
    userDB.set_history(session_id, data, category, role='ai')
    return JSONResponse(
        content={
            "state": status.HTTP_200_OK,
            "result": {
                "session_id": session_id,
                "type": screen_type,
                "source": [],
                "data": data,
                "plot": "",
                "relevant_query": "",
            },
            "message": "success"
        }
    )


@app.post("/analytest")
async def _analysis_llm(
    request: Request,
    input_data: str = Body(''),
    session_id: str = Body('tmp_session_id')
):
    '''
    í•­ë§Œë°ì´í„°ë¶„ì„ìš© LLM ì¶”ë¡  í•¨ìˆ˜
    args:
        input_data : ì‚¬ìš©ì ì…ë ¥ë°ì´í„°
        session_id : ëŒ€í™”ì°½ ì•„ì´ë””
    '''
    category = 'analysis'
    # ì‚¬ìš©ì ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    user_info = userDB.get_user_info(session_id, category)
    use_database = user_info['btn1']
    use_search = user_info['btn2']
    # ì´ì „ ëŒ€í™”ë“¤ê³ ì˜¤ê¸°
    conv_history = ConversationHistory(session_id)
    conv_history.get_history_chats()
    conv_history.get_histotry_format_prompt()
    prompt_state = {
        "CURRENT": {"MESSAGE": input_data},
        "HISTORY": conv_history.HISTORY
    }
    if not use_database:
        if not use_search:  # ì¼ë°˜ ëŒ€í™”
            logger.warning(f"ì¼ë°˜ ëŒ€í™”")
            response = general_answer_chain(prompt_state, conv_history)
            return StreamingResponse(wrapped_event_generator(response, session_id))
        else:  # ì›¹ì •ë³´ í™œìš©
            logger.warning(f"ì›¹ì •ë³´ í™œìš©")
            response = web_search_and_answer_chain(prompt_state, conv_history)
            return StreamingResponse(wrapped_event_generator(response, session_id))
    else:  # ë‚´ë¶€ DB ì‚¬ìš©
        logger.warning(f"ë‚´ë¶€ DB ì‚¬ìš©")
        previous_chats = conv_history.get_chats()
        if previous_chats:
            message = Chain__rewrite_request.invoke({
                "PREV_MESSAGE": previous_chats[-1]["user"],
                "PREV_SQL": previous_chats[-1].get("SQL"),
                "MESSAGE": input_data
            }).content
        else:
            message = input_data
        info_check, response, analysis_info = check_chain(
            message, extract_info)

        if info_check:
            # analysis ìƒì„± chain
            logger.warning(f"analysis ìƒì„± chain")
            response = _analysis_chain(
                user_info, prompt_state, category, analysis_info, conv_history
            )
            conv_history.add_chat(
                {"user": input_data,
                 "assistant": 'response'}
            )
            return StreamingResponse(wrapped_event_generator(response, session_id))

            # response = 'analysis ìƒì„± chain result'
            # return StreamingResponse(wrapped_string_generator(response, session_id))
        else:  # ì •ë³´ë¶€ì¡±
            # í•­êµ¬ì •ë³´, ì‹œê°„ ì •ë³´ ì ê²€ ê²°ê³¼ ë°˜í™˜
            logger.warning(f"í•­êµ¬ì •ë³´, ì‹œê°„ ì •ë³´ ì ê²€ ê²°ê³¼ ë°˜í™˜")
            conv_history.add_chat(
                {"user": input_data,
                 "assistant": response}
            )
            return StreamingResponse(wrapped_string_generator(response, session_id))


@app.post("/harbor_llm")
async def harbor_llm(
    request: Request,
    input_data: str = Body(''),
    session_id: str = Body('tmp_session_id')
) -> dict:
    '''
    í•­ë§Œë°ì´í„° ë¶„ì„ llm ì¶”ë¡  
    '''
    category = 'analysis'
    message_id = str(uuid.uuid4())[:6]
    conv_history = ConversationHistory(session_id)
    # ì‚¬ìš©ì ë¬¸ì ìˆëŠ”ì§€ ì—¬ë¶€ í™•ì¸
    if len(session_id.strip()) == 0:
        session_id = userDB.gen_session_id()
    # DBì— ì‚¬ìš©ì session_id ìˆëŠ”ì§€ í™•ì¸
    elif userDB.check_session_id(session_id):
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST, detail="session_id is not exist..")
    # ì´ˆê¸° ì§ˆë¬¸ ì‚¬ìš©ì ì •ë³´ì— ì €ì¥
    userDB.set_init_input(session_id, input_data, category)
    # ìœ ì € ì •ë³´ ë“¤ê³ ì˜´
    user_info = userDB.get_user_info(session_id, category)
    if user_info['init']:  # ì´ˆê¸° ëŒ€í™” ì‹œì‘
        screen_type = '1'
        data = "í¬íŠ¸ë¯¸ìŠ¤ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì‹œê² ìŠµë‹ˆê¹Œ?"
        conv_history.add_chat(
            {"user": input_data,
             "assistant": ''}
        )
        return StreamingResponse(wrapped_string_generator(data, session_id, screen_type, message_id))
    else:  # í†µê³„ìš© LLMì„ ì´ìš©í•œ ëŒ€í™”
        screen_type = '3'
        # í†µê³„ìš© LLM chain
        response = harbor_chain(input_data, session_id,
                                userDB, extract_info, message_id)
        return StreamingResponse(response)

if __name__ == "__main__":
    uvicorn.run("main:app", host=args.host,
                port=args.port, workers=1)
